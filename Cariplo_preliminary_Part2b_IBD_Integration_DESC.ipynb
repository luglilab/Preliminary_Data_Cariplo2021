{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1a13db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from matplotlib import colors\n",
    "import seaborn as sb\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67d2e855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os              \n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "import desc\n",
    "#import keras\n",
    "import tensorflow as tf\n",
    "from time import time                                                       \n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b3ef33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1be2c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(\"/mnt/lugli/spuccio/SP028_Autoimmunity/Cariplo/IBD_counts/h5files/Concatenated_obj_qc.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "242061b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 146798 × 16536\n",
       "    obs: 'CellId', 'CellFromTumor', 'PatientNumber', 'TumorType', 'TumorSite', 'CellType', 'dataset', 'batch', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'pct_counts_hb', 'percent_mt2', 'n_counts', 'n_genes'\n",
       "    var: 'gene_ids', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'n_cells', 'gene_biotype'\n",
       "    uns: 'PatientNumber_colors'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3edb2650",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.raw = adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daf8b08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata2 = adata.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d06528b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = adata2.to_df().loc[:,~adata2.to_df().columns.str.startswith('RPS')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eeb29e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146798, 16490)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9915b51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:,~df.columns.str.startswith('RPL')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c4eba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:,~df.columns.str.startswith('ACT')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee7ee33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:,~df.columns.str.startswith('MALAT1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4aad940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:,~df.columns.str.startswith('MT')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91615e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:,~df.columns.str.startswith('HB')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0f8a3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146798, 16323)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "243d2ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.AnnData(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b735ccf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs = adata2.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb9c2844",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata2 = adata.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63c0f187",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.normalize_total(adata, target_sum=1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa0c3dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc.log1p(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1604642",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c1fe7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, subset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16571b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HES4        True\n",
       "ISG15       True\n",
       "TTLL10      True\n",
       "TNFRSF18    True\n",
       "TNFRSF4     True\n",
       "MXRA8       True\n",
       "VWA1        True\n",
       "CFAP74      True\n",
       "SMIM1       True\n",
       "UTS2        True\n",
       "TNFRSF9     True\n",
       "NMNAT1      True\n",
       "RBP7        True\n",
       "DRAXIN      True\n",
       "C1orf167    True\n",
       "PDPN        True\n",
       "AKR7A3      True\n",
       "NBL1        True\n",
       "PLA2G2A     True\n",
       "PLA2G2D     True\n",
       "HSPG2       True\n",
       "C1QA        True\n",
       "C1QC        True\n",
       "C1QB        True\n",
       "ID3         True\n",
       "HMGCL       True\n",
       "CNR2        True\n",
       "NCMAP       True\n",
       "STMN1       True\n",
       "SLC30A2     True\n",
       "CNKSR1      True\n",
       "ZNF683      True\n",
       "SFN         True\n",
       "FCN3        True\n",
       "OPRD1       True\n",
       "SDC3        True\n",
       "TINAGL1     True\n",
       "FAM167B     True\n",
       "MARCKSL1    True\n",
       "ZBTB8A      True\n",
       "GJA4        True\n",
       "RHBDL2      True\n",
       "BMP8B       True\n",
       "ZFP69B      True\n",
       "GUCA2B      True\n",
       "GUCA2A      True\n",
       "TIE1        True\n",
       "PIK3R3      True\n",
       "STIL        True\n",
       "BEND5       True\n",
       "Name: highly_variable, dtype: bool"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.var['highly_variable'].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca9599e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.scale(adata,max_value=6,zero_center=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "614866e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata2.raw = adata2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52e54e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a113cd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to process resolution= 0.4\n",
      "The number of cpu in your computer is 32\n",
      "WARNING:tensorflow:From /home/spuccio/anaconda3/envs/DESC/lib/python3.6/site-packages/desc/models/desc.py:123: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n",
      "use_ae_weights=False, the program will rerun autoencoder\n",
      "Pretraining the 1th layer...\n",
      "learning rate = 0.1\n",
      "Train on 146798 samples\n",
      "Epoch 1/50\n",
      "146798/146798 [==============================] - 3s 19us/sample - loss: 0.4022\n",
      "Epoch 2/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3745\n",
      "Epoch 3/50\n",
      "146798/146798 [==============================] - 2s 17us/sample - loss: 0.3655\n",
      "Epoch 4/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3607\n",
      "Epoch 5/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3572\n",
      "Epoch 6/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3546\n",
      "Epoch 7/50\n",
      "146798/146798 [==============================] - 2s 17us/sample - loss: 0.3524\n",
      "Epoch 8/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3508\n",
      "Epoch 9/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3493\n",
      "Epoch 10/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3482\n",
      "Epoch 11/50\n",
      "146798/146798 [==============================] - 3s 17us/sample - loss: 0.3472\n",
      "Epoch 12/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3464\n",
      "Epoch 13/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3457\n",
      "Epoch 14/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3452\n",
      "Epoch 15/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3447\n",
      "Epoch 16/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3443\n",
      "Epoch 17/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3439\n",
      "Epoch 18/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3436\n",
      "Epoch 19/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3433\n",
      "Epoch 20/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3431\n",
      "Epoch 21/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3429\n",
      "Epoch 22/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3426\n",
      "Epoch 23/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3425\n",
      "Epoch 24/50\n",
      "146798/146798 [==============================] - 2s 17us/sample - loss: 0.3422\n",
      "Epoch 25/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3422\n",
      "Epoch 26/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3420\n",
      "Epoch 27/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3418\n",
      "Epoch 28/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3416\n",
      "Epoch 29/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3415\n",
      "Epoch 30/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3414\n",
      "Epoch 31/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3413\n",
      "Epoch 32/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3413\n",
      "Epoch 33/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3410\n",
      "Epoch 34/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3409\n",
      "Epoch 35/50\n",
      "146798/146798 [==============================] - 2s 17us/sample - loss: 0.3409\n",
      "Epoch 36/50\n",
      "146798/146798 [==============================] - 2s 17us/sample - loss: 0.3408\n",
      "Epoch 37/50\n",
      "146798/146798 [==============================] - 2s 17us/sample - loss: 0.3407\n",
      "Epoch 38/50\n",
      "146798/146798 [==============================] - 2s 17us/sample - loss: 0.3406\n",
      "Epoch 39/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3405\n",
      "Epoch 40/50\n",
      "146798/146798 [==============================] - 2s 17us/sample - loss: 0.3405\n",
      "Epoch 41/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3404\n",
      "Epoch 42/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3403\n",
      "Epoch 43/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3403\n",
      "Epoch 44/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3402\n",
      "Epoch 45/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3402\n",
      "Epoch 46/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3401\n",
      "Epoch 47/50\n",
      "146798/146798 [==============================] - 2s 17us/sample - loss: 0.3399\n",
      "Epoch 48/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3400\n",
      "Epoch 49/50\n",
      "146798/146798 [==============================] - 2s 17us/sample - loss: 0.3399\n",
      "Epoch 50/50\n",
      "146798/146798 [==============================] - 2s 17us/sample - loss: 0.3399\n",
      "learning rate = 0.01\n",
      "Train on 146798 samples\n",
      "Epoch 1/50\n",
      "146798/146798 [==============================] - 3s 18us/sample - loss: 0.3398\n",
      "Epoch 2/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3397\n",
      "Epoch 3/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3397\n",
      "Epoch 4/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3396\n",
      "Epoch 5/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3396\n",
      "Epoch 6/50\n",
      "146798/146798 [==============================] - 2s 17us/sample - loss: 0.3396\n",
      "Epoch 7/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3396\n",
      "Epoch 8/50\n",
      "146798/146798 [==============================] - 2s 17us/sample - loss: 0.3397\n",
      "Epoch 9/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3396\n",
      "Epoch 10/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3396\n",
      "Epoch 11/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3396\n",
      "Epoch 12/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3396\n",
      "Epoch 13/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3396\n",
      "Epoch 14/50\n",
      "146798/146798 [==============================] - 2s 17us/sample - loss: 0.3396\n",
      "Epoch 00014: early stopping\n",
      "learning rate = 0.001\n",
      "Train on 146798 samples\n",
      "Epoch 1/50\n",
      "146798/146798 [==============================] - 3s 18us/sample - loss: 0.3396\n",
      "Epoch 2/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3396\n",
      "Epoch 3/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3396\n",
      "Epoch 4/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3395\n",
      "Epoch 5/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3395\n",
      "Epoch 6/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3395\n",
      "Epoch 7/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3396\n",
      "Epoch 8/50\n",
      "146798/146798 [==============================] - 2s 17us/sample - loss: 0.3396\n",
      "Epoch 9/50\n",
      "146798/146798 [==============================] - 2s 17us/sample - loss: 0.3395\n",
      "Epoch 10/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3396\n",
      "Epoch 11/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3396\n",
      "Epoch 12/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3395\n",
      "Epoch 13/50\n",
      "146798/146798 [==============================] - 2s 17us/sample - loss: 0.3395\n",
      "Epoch 14/50\n",
      "146798/146798 [==============================] - 2s 17us/sample - loss: 0.3395\n",
      "Epoch 15/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3395\n",
      "Epoch 00015: early stopping\n",
      "The 1th layer has been pretrained.\n",
      "Pretraining the 2th layer...\n",
      "learning rate = 0.1\n",
      "Train on 146798 samples\n",
      "Epoch 1/50\n",
      "146798/146798 [==============================] - 1s 7us/sample - loss: 0.7339\n",
      "Epoch 2/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.5252\n",
      "Epoch 3/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.5095\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.5081\n",
      "Epoch 5/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.5116\n",
      "Epoch 6/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.5110\n",
      "Epoch 7/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.5124\n",
      "Epoch 8/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.5032\n",
      "Epoch 9/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4964\n",
      "Epoch 10/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4944\n",
      "Epoch 11/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4946\n",
      "Epoch 12/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4974\n",
      "Epoch 13/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4957\n",
      "Epoch 14/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.5016\n",
      "Epoch 15/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4963\n",
      "Epoch 16/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4939\n",
      "Epoch 17/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4949\n",
      "Epoch 18/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4929\n",
      "Epoch 19/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4904\n",
      "Epoch 20/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4891\n",
      "Epoch 21/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4983\n",
      "Epoch 22/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4981\n",
      "Epoch 23/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4855\n",
      "Epoch 24/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4923\n",
      "Epoch 25/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4938\n",
      "Epoch 26/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4881\n",
      "Epoch 27/50\n",
      "146798/146798 [==============================] - 1s 6us/sample - loss: 0.4967\n",
      "Epoch 28/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4963\n",
      "Epoch 29/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4830\n",
      "Epoch 30/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4866\n",
      "Epoch 31/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4892\n",
      "Epoch 32/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4932\n",
      "Epoch 33/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4971\n",
      "Epoch 34/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4934\n",
      "Epoch 35/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4980\n",
      "Epoch 36/50\n",
      "146798/146798 [==============================] - 1s 6us/sample - loss: 0.4979\n",
      "Epoch 37/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4847\n",
      "Epoch 38/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4939\n",
      "Epoch 39/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.5000\n",
      "Epoch 00039: early stopping\n",
      "learning rate = 0.01\n",
      "Train on 146798 samples\n",
      "Epoch 1/50\n",
      "146798/146798 [==============================] - 1s 7us/sample - loss: 0.4818\n",
      "Epoch 2/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4739\n",
      "Epoch 3/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4709\n",
      "Epoch 4/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4663\n",
      "Epoch 5/50\n",
      "146798/146798 [==============================] - 1s 6us/sample - loss: 0.4626\n",
      "Epoch 6/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4622\n",
      "Epoch 7/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4599\n",
      "Epoch 8/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4605\n",
      "Epoch 9/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4545\n",
      "Epoch 10/50\n",
      "146798/146798 [==============================] - 1s 6us/sample - loss: 0.4519\n",
      "Epoch 11/50\n",
      "146798/146798 [==============================] - 1s 6us/sample - loss: 0.4537\n",
      "Epoch 12/50\n",
      "146798/146798 [==============================] - 1s 6us/sample - loss: 0.4509\n",
      "Epoch 13/50\n",
      "146798/146798 [==============================] - 1s 6us/sample - loss: 0.4529\n",
      "Epoch 14/50\n",
      "146798/146798 [==============================] - 1s 6us/sample - loss: 0.4544\n",
      "Epoch 15/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4484\n",
      "Epoch 16/50\n",
      "146798/146798 [==============================] - 1s 6us/sample - loss: 0.4510\n",
      "Epoch 17/50\n",
      "146798/146798 [==============================] - 1s 6us/sample - loss: 0.4483\n",
      "Epoch 18/50\n",
      "146798/146798 [==============================] - 1s 6us/sample - loss: 0.4476\n",
      "Epoch 19/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4447\n",
      "Epoch 20/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4455\n",
      "Epoch 21/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4462\n",
      "Epoch 22/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4458\n",
      "Epoch 23/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4426\n",
      "Epoch 24/50\n",
      "146798/146798 [==============================] - 1s 6us/sample - loss: 0.4425\n",
      "Epoch 25/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4439\n",
      "Epoch 26/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4399\n",
      "Epoch 27/50\n",
      "146798/146798 [==============================] - 1s 6us/sample - loss: 0.4449\n",
      "Epoch 28/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4404\n",
      "Epoch 29/50\n",
      "146798/146798 [==============================] - 1s 6us/sample - loss: 0.4360\n",
      "Epoch 30/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4381\n",
      "Epoch 31/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4374\n",
      "Epoch 32/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4364\n",
      "Epoch 33/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4394\n",
      "Epoch 34/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4373\n",
      "Epoch 35/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4374\n",
      "Epoch 36/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4359\n",
      "Epoch 37/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4338\n",
      "Epoch 38/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4315\n",
      "Epoch 39/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4390\n",
      "Epoch 40/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4355\n",
      "Epoch 41/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4332\n",
      "Epoch 42/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4349\n",
      "Epoch 43/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4334\n",
      "Epoch 44/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4335\n",
      "Epoch 45/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4332\n",
      "Epoch 46/50\n",
      "146798/146798 [==============================] - 1s 6us/sample - loss: 0.4341\n",
      "Epoch 47/50\n",
      "146798/146798 [==============================] - 1s 6us/sample - loss: 0.4351\n",
      "Epoch 48/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4329\n",
      "Epoch 00048: early stopping\n",
      "learning rate = 0.001\n",
      "Train on 146798 samples\n",
      "Epoch 1/50\n",
      "146798/146798 [==============================] - 1s 7us/sample - loss: 0.4282\n",
      "Epoch 2/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4267\n",
      "Epoch 3/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4276\n",
      "Epoch 4/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4267\n",
      "Epoch 5/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4250\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4277\n",
      "Epoch 7/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4254\n",
      "Epoch 8/50\n",
      "146798/146798 [==============================] - 1s 6us/sample - loss: 0.4264\n",
      "Epoch 9/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4242\n",
      "Epoch 10/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4210\n",
      "Epoch 11/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4232\n",
      "Epoch 12/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4229\n",
      "Epoch 13/50\n",
      "146798/146798 [==============================] - 1s 6us/sample - loss: 0.4242\n",
      "Epoch 14/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4279\n",
      "Epoch 15/50\n",
      "146798/146798 [==============================] - 1s 5us/sample - loss: 0.4217\n",
      "Epoch 16/50\n",
      "146798/146798 [==============================] - 1s 6us/sample - loss: 0.4266\n",
      "Epoch 17/50\n",
      "146798/146798 [==============================] - 1s 6us/sample - loss: 0.4255\n",
      "Epoch 18/50\n",
      "146798/146798 [==============================] - 1s 6us/sample - loss: 0.4249\n",
      "Epoch 19/50\n",
      "146798/146798 [==============================] - 1s 6us/sample - loss: 0.4227\n",
      "Epoch 20/50\n",
      "146798/146798 [==============================] - 1s 6us/sample - loss: 0.4239\n",
      "Epoch 00020: early stopping\n",
      "The 2th layer has been pretrained.\n",
      "Copying layer-wise pretrained weights to deep autoencoders\n",
      "Fine-tuning autoencoder end-to-end\n",
      "learning rate = 1\n",
      "Train on 146798 samples\n",
      "Epoch 1/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3401\n",
      "Epoch 2/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3374\n",
      "Epoch 3/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3364\n",
      "Epoch 4/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3358\n",
      "Epoch 5/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3353\n",
      "Epoch 6/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3348\n",
      "Epoch 7/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3345\n",
      "Epoch 8/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3342\n",
      "Epoch 9/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3340\n",
      "Epoch 10/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3339\n",
      "Epoch 11/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3336\n",
      "Epoch 12/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3335\n",
      "Epoch 13/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3333\n",
      "Epoch 14/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3332\n",
      "Epoch 15/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3331\n",
      "Epoch 16/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3330\n",
      "Epoch 17/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3329\n",
      "Epoch 18/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3328\n",
      "Epoch 19/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3328\n",
      "Epoch 20/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3326\n",
      "Epoch 21/50\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3326\n",
      "Epoch 22/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3325\n",
      "Epoch 23/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3324\n",
      "Epoch 24/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3323\n",
      "Epoch 25/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3323\n",
      "Epoch 26/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3322\n",
      "Epoch 27/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3321\n",
      "Epoch 28/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3320\n",
      "Epoch 29/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3319\n",
      "Epoch 30/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3319\n",
      "Epoch 31/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3318\n",
      "Epoch 32/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3318\n",
      "Epoch 33/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3317\n",
      "Epoch 34/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3316\n",
      "Epoch 35/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3316\n",
      "Epoch 36/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3315\n",
      "Epoch 37/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3314\n",
      "Epoch 38/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3314\n",
      "Epoch 39/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3313\n",
      "Epoch 40/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3313\n",
      "Epoch 41/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3312\n",
      "Epoch 42/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3312\n",
      "Epoch 43/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3311\n",
      "Epoch 44/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3310\n",
      "Epoch 45/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3310\n",
      "Epoch 46/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3310\n",
      "Epoch 47/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3308\n",
      "Epoch 48/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3308\n",
      "Epoch 49/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3307\n",
      "Epoch 50/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3307\n",
      "learning rate = 0.1\n",
      "Train on 146798 samples\n",
      "Epoch 1/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3299\n",
      "Epoch 2/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3298\n",
      "Epoch 3/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3297\n",
      "Epoch 4/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3297\n",
      "Epoch 5/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3297\n",
      "Epoch 6/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3297\n",
      "Epoch 7/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3296\n",
      "Epoch 8/50\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3296\n",
      "Epoch 9/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3296\n",
      "Epoch 10/50\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3296\n",
      "Epoch 11/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3296\n",
      "Epoch 12/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3296\n",
      "Epoch 13/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3296\n",
      "Epoch 14/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3296\n",
      "Epoch 15/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3295\n",
      "Epoch 16/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3295\n",
      "Epoch 17/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3295\n",
      "Epoch 18/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3295\n",
      "Epoch 19/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3295\n",
      "Epoch 20/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3295\n",
      "Epoch 21/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3295\n",
      "Epoch 22/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3295\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3295\n",
      "Epoch 24/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3295\n",
      "Epoch 00024: early stopping\n",
      "learning rate = 0.01\n",
      "Train on 146798 samples\n",
      "Epoch 1/50\n",
      "146798/146798 [==============================] - 2s 15us/sample - loss: 0.3294\n",
      "Epoch 2/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3294\n",
      "Epoch 3/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3294\n",
      "Epoch 4/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3294\n",
      "Epoch 5/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3294\n",
      "Epoch 6/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3294\n",
      "Epoch 7/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3294\n",
      "Epoch 8/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3294\n",
      "Epoch 9/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3294\n",
      "Epoch 10/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3294\n",
      "Epoch 11/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3294\n",
      "Epoch 00011: early stopping\n",
      "learning rate = 0.001\n",
      "Train on 146798 samples\n",
      "Epoch 1/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3293\n",
      "Epoch 2/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3293\n",
      "Epoch 3/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3293\n",
      "Epoch 4/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3293\n",
      "Epoch 5/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3293\n",
      "Epoch 6/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3293\n",
      "Epoch 7/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3293\n",
      "Epoch 8/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3293\n",
      "Epoch 9/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3293\n",
      "Epoch 10/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3293\n",
      "Epoch 11/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3293\n",
      "Epoch 00011: early stopping\n",
      "learning rate = 0.0001\n",
      "Train on 146798 samples\n",
      "Epoch 1/50\n",
      "146798/146798 [==============================] - 2s 16us/sample - loss: 0.3293\n",
      "Epoch 2/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3293\n",
      "Epoch 3/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3293\n",
      "Epoch 4/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3293\n",
      "Epoch 5/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3293\n",
      "Epoch 6/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3293\n",
      "Epoch 7/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3293\n",
      "Epoch 8/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3293\n",
      "Epoch 9/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3293\n",
      "Epoch 10/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3293\n",
      "Epoch 11/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3293\n",
      "Epoch 00011: early stopping\n",
      "learning rate = 1e-05\n",
      "Train on 146798 samples\n",
      "Epoch 1/50\n",
      "146798/146798 [==============================] - 2s 15us/sample - loss: 0.3293\n",
      "Epoch 2/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3293\n",
      "Epoch 3/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3293\n",
      "Epoch 4/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3293\n",
      "Epoch 5/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3293\n",
      "Epoch 6/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3293\n",
      "Epoch 7/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3293\n",
      "Epoch 8/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3293\n",
      "Epoch 9/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3293\n",
      "Epoch 10/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3293\n",
      "Epoch 11/50\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.3293\n",
      "Epoch 00011: early stopping\n",
      "Pretraining time is 532.9127943515778\n",
      "Pretrained weights are saved to /mnt/lugli/TempFolder /ae_weights.h5\n",
      "...number of clusters is unknown, Initialize cluster centroid using louvain method\n",
      "The value of delta_label of current 1 th iteration is 0.1180261311462009 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.0398\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.0289\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.0249\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.0225\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 11us/sample - loss: 0.0207\n",
      "The value of delta_label of current 2 th iteration is 0.09889780514720908 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.1143\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.0887\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.0748\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.0657\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.0596\n",
      "The value of delta_label of current 3 th iteration is 0.06790283246365754 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2071\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.1722\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.1514\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.1375\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.1271\n",
      "The value of delta_label of current 4 th iteration is 0.05808662243354814 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2620\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2341\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2170\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2052\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.1958\n",
      "The value of delta_label of current 5 th iteration is 0.04228940448779956 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2855\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2672\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2543\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2432\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2344\n",
      "The value of delta_label of current 6 th iteration is 0.029087589749179143 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2973\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2820\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2708\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2621\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2550\n",
      "The value of delta_label of current 7 th iteration is 0.017418493439965124 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2978\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2878\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2791\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2716\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2644\n",
      "The value of delta_label of current 8 th iteration is 0.011723592964481805 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2899\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2812\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2741\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2676\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2617\n",
      "The value of delta_label of current 9 th iteration is 0.008092753307265766 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2796\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2727\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 11us/sample - loss: 0.2671\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2619\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2579\n",
      "The value of delta_label of current 10 th iteration is 0.005470101772503713 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2722\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2685\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2654\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2628\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2604\n",
      "delta_label  0.004312047848063325 < tol  0.005\n",
      "Reached tolerance threshold. Stop training.\n",
      "The final prediction cluster is:\n",
      "0     27985\n",
      "1     16230\n",
      "2     16982\n",
      "3     10829\n",
      "4      9716\n",
      "5      9275\n",
      "6     12747\n",
      "7      8478\n",
      "8      4615\n",
      "9      4500\n",
      "10     4386\n",
      "11     3627\n",
      "12     7688\n",
      "13     2716\n",
      "14     2285\n",
      "15     1705\n",
      "16     1581\n",
      "17      829\n",
      "18      624\n",
      "dtype: int64\n",
      "The desc has been trained successfully!!!!!!\n",
      "The summary of desc model is:\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 1470)]            0         \n",
      "_________________________________________________________________\n",
      "encoder_0 (Dense)            (None, 64)                94144     \n",
      "_________________________________________________________________\n",
      "encoder_1 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "clustering (ClusteringLayer) (None, 19)                608       \n",
      "=================================================================\n",
      "Total params: 96,832\n",
      "Trainable params: 96,832\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "The runtime of (resolution=0.4)is: 743.1901204586029\n",
      "umap finished and added X_umap0.4  into the umap coordinates (adata.obsm)\n",
      "\n",
      "Start to process resolution= 0.5\n",
      "The number of cpu in your computer is 32\n",
      "Checking whether /mnt/lugli/TempFolder/ae_weights.h5  exists in the directory\n",
      "Pretraining time is 0.016143083572387695\n",
      "...number of clusters is unknown, Initialize cluster centroid using louvain method\n",
      "The value of delta_label of current 1 th iteration is 0.14264499516342186 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 15us/sample - loss: 0.0405\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.0300\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.0260\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.0236\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.0218\n",
      "The value of delta_label of current 2 th iteration is 0.09801223449910762 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.1158\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.0918\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.0785\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.0698\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.0635\n",
      "The value of delta_label of current 3 th iteration is 0.07158816877614137 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2124\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.1767\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.1553\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.1406\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.1298\n",
      "The value of delta_label of current 4 th iteration is 0.06604994618455293 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.2785\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2484\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2294\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2153\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2042\n",
      "The value of delta_label of current 5 th iteration is 0.047984304963282876 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3105\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2887\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2743\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2632\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2541\n",
      "The value of delta_label of current 6 th iteration is 0.030347824902246624 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3250\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3102\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2983\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2887\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2810\n",
      "The value of delta_label of current 7 th iteration is 0.020156950367171213 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3259\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3159\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3068\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2990\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2921\n",
      "The value of delta_label of current 8 th iteration is 0.0137331571274813 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3202\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3126\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3062\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3008\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2960\n",
      "The value of delta_label of current 9 th iteration is 0.010020572487363589 >= tol 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3151\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3087\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3034\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2992\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2958\n",
      "The value of delta_label of current 10 th iteration is 0.007145873921988038 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3106\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3062\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3024\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2986\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2955\n",
      "delta_label  0.004843390236924209 < tol  0.005\n",
      "Reached tolerance threshold. Stop training.\n",
      "The final prediction cluster is:\n",
      "0     20755\n",
      "1     15972\n",
      "2     15501\n",
      "3     10875\n",
      "4      9628\n",
      "5      9598\n",
      "6     12830\n",
      "7     10618\n",
      "8      7220\n",
      "9      4610\n",
      "10     4145\n",
      "11     4532\n",
      "12     3688\n",
      "13     7165\n",
      "14     2650\n",
      "15     1966\n",
      "16     1611\n",
      "17     1567\n",
      "18      841\n",
      "19      627\n",
      "20      399\n",
      "dtype: int64\n",
      "The desc has been trained successfully!!!!!!\n",
      "The summary of desc model is:\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 1470)]            0         \n",
      "_________________________________________________________________\n",
      "encoder_0 (Dense)            (None, 64)                94144     \n",
      "_________________________________________________________________\n",
      "encoder_1 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "clustering (ClusteringLayer) (None, 21)                672       \n",
      "=================================================================\n",
      "Total params: 96,896\n",
      "Trainable params: 96,896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "The runtime of (resolution=0.5)is: 180.62582993507385\n",
      "umap finished and added X_umap0.5  into the umap coordinates (adata.obsm)\n",
      "\n",
      "Start to process resolution= 0.6\n",
      "The number of cpu in your computer is 32\n",
      "Checking whether /mnt/lugli/TempFolder/ae_weights.h5  exists in the directory\n",
      "Pretraining time is 0.012450933456420898\n",
      "...number of clusters is unknown, Initialize cluster centroid using louvain method\n",
      "The value of delta_label of current 1 th iteration is 0.16115342170874264 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 14us/sample - loss: 0.0415\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.0311\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.0271\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.0246\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.0227\n",
      "The value of delta_label of current 2 th iteration is 0.094401831087617 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.1184\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.0943\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.0810\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.0720\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.0655\n",
      "The value of delta_label of current 3 th iteration is 0.07919045218599709 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2142\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.1789\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.1580\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.1439\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.1330\n",
      "The value of delta_label of current 4 th iteration is 0.07583890788702843 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2841\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2537\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2332\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2187\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2079\n",
      "The value of delta_label of current 5 th iteration is 0.055130178885270914 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3183\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2962\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2817\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2705\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2612\n",
      "The value of delta_label of current 6 th iteration is 0.038018229131187076 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3338\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3170\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3048\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2955\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.2878\n",
      "The value of delta_label of current 7 th iteration is 0.02772517336748457 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3360\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3248\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3155\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3080\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3016\n",
      "The value of delta_label of current 8 th iteration is 0.01722775514652788 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3333\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3255\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3190\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3132\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3073\n",
      "The value of delta_label of current 9 th iteration is 0.011328492213790379 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3277\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3216\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3156\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3093\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3043\n",
      "The value of delta_label of current 10 th iteration is 0.008058692897723402 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3207\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3164\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3121\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3087\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3055\n",
      "The value of delta_label of current 11 th iteration is 0.005374732625785092 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3165\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3133\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3099\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3071\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3044\n",
      "delta_label  0.0040055041621820464 < tol  0.005\n",
      "Reached tolerance threshold. Stop training.\n",
      "The final prediction cluster is:\n",
      "0     18167\n",
      "1     13569\n",
      "2     14531\n",
      "3     11443\n",
      "4      9787\n",
      "5      8459\n",
      "6     13520\n",
      "7     11363\n",
      "8     10723\n",
      "9      4609\n",
      "10     5298\n",
      "11     3802\n",
      "12     3546\n",
      "13     2794\n",
      "14     1980\n",
      "15     1618\n",
      "16     5181\n",
      "17     1569\n",
      "18     2996\n",
      "19      829\n",
      "20      622\n",
      "21      392\n",
      "dtype: int64\n",
      "The desc has been trained successfully!!!!!!\n",
      "The summary of desc model is:\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 1470)]            0         \n",
      "_________________________________________________________________\n",
      "encoder_0 (Dense)            (None, 64)                94144     \n",
      "_________________________________________________________________\n",
      "encoder_1 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "clustering (ClusteringLayer) (None, 22)                704       \n",
      "=================================================================\n",
      "Total params: 96,928\n",
      "Trainable params: 96,928\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "The runtime of (resolution=0.6)is: 193.50208115577698\n",
      "umap finished and added X_umap0.6  into the umap coordinates (adata.obsm)\n",
      "\n",
      "Start to process resolution= 0.8\n",
      "The number of cpu in your computer is 32\n",
      "Checking whether /mnt/lugli/TempFolder/ae_weights.h5  exists in the directory\n",
      "Pretraining time is 0.014153003692626953\n",
      "...number of clusters is unknown, Initialize cluster centroid using louvain method\n",
      "The value of delta_label of current 1 th iteration is 0.19165111241297567 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 15us/sample - loss: 0.0479\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.0377\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.0337\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.0310\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.0290\n",
      "The value of delta_label of current 2 th iteration is 0.11276039183095138 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.1261\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.1061\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.0943\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.0856\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.0791\n",
      "The value of delta_label of current 3 th iteration is 0.10390468534993665 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.2241\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.1913\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.1701\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.1548\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.1442\n",
      "The value of delta_label of current 4 th iteration is 0.09719478467009088 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3060\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.2749\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.2534\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.2377\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.2262\n",
      "The value of delta_label of current 5 th iteration is 0.08991266910993338 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3510\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3277\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3120\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.2997\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.2886\n",
      "The value of delta_label of current 6 th iteration is 0.07439474652243219 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3693\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3514\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3378\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3267\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3170\n",
      "The value of delta_label of current 7 th iteration is 0.047670949195493126 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3752\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3626\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3531\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3445\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3369\n",
      "The value of delta_label of current 8 th iteration is 0.029162522650172346 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3778\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3687\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3616\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3561\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3514\n",
      "The value of delta_label of current 9 th iteration is 0.020892655213286284 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3793\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3733\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3680\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3630\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3589\n",
      "The value of delta_label of current 10 th iteration is 0.015143258082535185 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3792\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3743\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3701\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3662\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3626\n",
      "The value of delta_label of current 11 th iteration is 0.011594163408220821 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3794\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3752\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3716\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3684\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3655\n",
      "The value of delta_label of current 12 th iteration is 0.009366612624150193 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 15us/sample - loss: 0.3790\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3754\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3723\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3693\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3663\n",
      "The value of delta_label of current 13 th iteration is 0.007329800133516805 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3771\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3733\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3699\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3670\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3644\n",
      "The value of delta_label of current 14 th iteration is 0.006198994536710309 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3751\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 12us/sample - loss: 0.3723\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3697\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3675\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3655\n",
      "The value of delta_label of current 15 th iteration is 0.005231678905707162 >= tol 0.005\n",
      "Train on 146798 samples\n",
      "Epoch 1/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3737\n",
      "Epoch 2/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3714\n",
      "Epoch 3/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3692\n",
      "Epoch 4/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3673\n",
      "Epoch 5/5\n",
      "146798/146798 [==============================] - 2s 13us/sample - loss: 0.3655\n",
      "delta_label  0.0038692625240125886 < tol  0.005\n",
      "Reached tolerance threshold. Stop training.\n",
      "The final prediction cluster is:\n",
      "0      7991\n",
      "1     12605\n",
      "2     12916\n",
      "3     12066\n",
      "4     10943\n",
      "5     11289\n",
      "6      9749\n",
      "7      9934\n",
      "8      9411\n",
      "9      5644\n",
      "10     9947\n",
      "11     1700\n",
      "12     3428\n",
      "13     4320\n",
      "14     3599\n",
      "15     2323\n",
      "16     2740\n",
      "17     1613\n",
      "18     2297\n",
      "19     5099\n",
      "20     1790\n",
      "21     1122\n",
      "22      987\n",
      "23      852\n",
      "24      814\n",
      "25      613\n",
      "26      622\n",
      "27      384\n",
      "dtype: int64\n",
      "The desc has been trained successfully!!!!!!\n",
      "The summary of desc model is:\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 1470)]            0         \n",
      "_________________________________________________________________\n",
      "encoder_0 (Dense)            (None, 64)                94144     \n",
      "_________________________________________________________________\n",
      "encoder_1 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "clustering (ClusteringLayer) (None, 29)                928       \n",
      "=================================================================\n",
      "Total params: 97,152\n",
      "Trainable params: 97,152\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "The runtime of (resolution=0.8)is: 258.6297273635864\n",
      "umap finished and added X_umap0.8  into the umap coordinates (adata.obsm)\n",
      "\n",
      "The run time for all resolution is: 2600.120863676071\n",
      "After training, the information of adata is:\n",
      " AnnData object with n_obs × n_vars = 146798 × 1470\n",
      "    obs: 'CellId', 'CellFromTumor', 'PatientNumber', 'TumorType', 'TumorSite', 'CellType', 'dataset', 'batch', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'pct_counts_hb', 'percent_mt2', 'n_counts', 'n_genes', 'desc_0.4', 'desc_0.5', 'desc_0.6', 'desc_0.8'\n",
      "    var: 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'\n",
      "    uns: 'log1p', 'hvg', 'umap', 'prob_matrix0.4', 'prob_matrix0.5', 'prob_matrix0.6', 'prob_matrix0.8'\n",
      "    obsm: 'X_Embeded_z0.4', 'X_umap', 'X_umap0.4', 'X_Embeded_z0.5', 'X_umap0.5', 'X_Embeded_z0.6', 'X_umap0.6', 'X_Embeded_z0.8', 'X_umap0.8'\n",
      "    obsp: 'distances', 'connectivities'\n"
     ]
    }
   ],
   "source": [
    "save_dir=\"/mnt/lugli/TempFolder\"\n",
    "adata=desc.train(adata,\n",
    "        dims=[adata.shape[1],64,32],\n",
    "        tol=0.005,\n",
    "        n_neighbors=10,\n",
    "        batch_size=256,\n",
    "        louvain_resolution=[0.4,0.5,0.6,0.8],# not necessarily a list, you can only set one value, like, louvain_resolution=1.0\n",
    "        save_dir=str(save_dir),\n",
    "        do_tsne=False,\n",
    "        learning_rate=200, # the parameter of tsne\n",
    "        use_GPU=False,\n",
    "        num_Cores=30,\n",
    "        num_Cores_tsne=4,\n",
    "        save_encoder_weights=False,\n",
    "        save_encoder_step=3,# save_encoder_weights is False, this parameter is not used\n",
    "        use_ae_weights=False,\n",
    "        do_umap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c8a174e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata2.obs = adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "508324e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata2.obsm = adata.obsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37f751a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 146798 × 16323\n",
       "    obs: 'CellId', 'CellFromTumor', 'PatientNumber', 'TumorType', 'TumorSite', 'CellType', 'dataset', 'batch', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'pct_counts_hb', 'percent_mt2', 'n_counts', 'n_genes', 'desc_0.4', 'desc_0.5', 'desc_0.6', 'desc_0.8'\n",
       "    obsm: 'X_Embeded_z0.4', 'X_umap', 'X_umap0.4', 'X_Embeded_z0.5', 'X_umap0.5', 'X_Embeded_z0.6', 'X_umap0.6', 'X_Embeded_z0.8', 'X_umap0.8'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc72b271",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata2.write(\"/mnt/lugli/spuccio/SP028_Autoimmunity/Cariplo/IBD_counts/h5files/DESC_obj_onlyIBD.h5ad\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
